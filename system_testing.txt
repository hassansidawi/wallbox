In traditional software development, code can be built and tests can be automated in production-like environments.
It is very mature in the web development space, and increasingly so in mobile app development as well.

In the embedded world, the interplay between hardware and software made things more difficult.

A different approach must be considered when hardware is involved.
Connected objects need to converse with each other to function properly.

This means that developers must consider ways to streamline device-to-device (D2D) and device-to-server (D2S) communication,
in addition to the human interaction that comes into play as everyday objects become an extension of the Internet.

Habitually, systems involving integration between hardware and software require:
- The ability to gather sensor data by reacting to a variety of inputs like touch, voice and motion tracking;
- Different types of interoperating hardware (boards, machines, cameras);
- Cloud-based servers, mobile and web applications from which the devices can be monitored and controlled;
- A Device API to enable routine data and device diagnostics pulls to cloud servers, as well as functionality manipulation.

The integration needs also to consider different communication protocols in addition to Wi-Fi and Bluetooth.

Furthermore, embedded systems are subjected to regulatory requirements to ensure the safety and reliability of programmable electronic devices.

In general, the ability to decouple programming logic from hardware makes for easier subsystem testing. 

As a first try, testers can record input data from real world users and environmental data, to be replayed in test environments.
This helps to keep test environments as production-like as possible.

Additionally, Compliance testing against regulatory requirements can be partially automated using static analysis tools.

Modern approaches to testing composite applications featuring embedded software involve some form of SIMULATION.

Like mobile app developers that use emulators to recreate test conditions across a variety of smartphones, embedded software developers can use simulation software to abstract away parts of their continuous testing environments.

Simulations resolve the problems of hardware availability and accelerate tests against various versions, screen sizes, and other hardware properties.

These virtualized environments are specific to each application and tend to be expensive to set up.
However, the initial effort pays back for itself many times over as the project’s life extends.

In such virtual environment, the Hardware and the outside world are replaced by a simulation so that the entire setup becomes purely software-based.

These simulators support performance and memory testing, security testing, and fault injection, like dropped connections or electromagnetic interference creating noise in sensor data.

Nevertheless, teams may never rely entirely on simulations and a real hardware is still necessary at the tail end of each major testing cycle.
Errors and approximations in the simulation can cause imperfections that must be caught before the product certification. 

In addition, human interaction testing and emergent behaviors can’t be simulated.
A person’s emotional response to even a perfectly functional hardware-enabled system can be difficult to predict.

A combination of white-box testing and black-box testing is usually employed during the QA phase to detect problems that might have fallen through the simulation’s cracks.
